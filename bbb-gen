#!/usr/bin/env python3
import argparse
from bs4 import BeautifulSoup
from pathlib import Path
from selenium import webdriver
from selenium.webdriver.firefox.options import Options
import urllib.request
import yaml


def _generate_url(options):
  if not options:
    raise ValueError('Options cannot be empty.')
  # Assumes the cycle is using the exact settings that I currently use, only the TM's are customizable
  # UB goes up 5 lbs per cycle, LB goes up 10 lbs per cycle
  url = ('https://blackironbeast.com/5/3/1/calculator?'
        'assistanceWork=boringButBig&massUnits=pounds&maxesSwitch=trainingMax'
        f'&militaryTrainingMaxWeight={options["ohp"]}&benchTrainingMaxWeight={options["bench"]}&squatTrainingMaxWeight={options["squat"]}&deadliftTrainingMaxWeight={options["deadlift"]}'
        '&barWeight=45&platePairs_100=0&platePairs_55=0&platePairs_45=1&platePairs_35=1&platePairs_25=1&platePairs_20=0'
        '&platePairs_15=0&platePairs_10=1&platePairs_7_5=0&platePairs_5=2&platePairs_2_5=1&platePairs_2=0&platePairs_1_5=0'
        '&platePairs_1_25=0&platePairs_1=0&platePairs_0_75=0&platePairs_0_5=0&platePairs_0_25=0&warmup=defranco'
        '&programming=fresher&weeksOrder=531D&order=normal&extraSets=noneExtraSets&firstSetLastSetsSelect=3&firstSetLastRepsSelect=5'
        '&boringButBigOption=across50&boringButBigSwapOption=lessBoring&daysPerWeekOption=4&fullBodyPhaseOption=1'
        '&fullBodyFullBoringSquatOption=65x5_75x5_85x5&fullBodyFullBoringBenchOption=65x5_75x5_85x5'
        '&fullBodyFullBoringDeadliftOption=65x3_75x3_85x3&boringButBig3MonthChallengeMonthOption=1&buildingTheMonolithWaveOption=1'
        '&youngJimWendlerSeasonOption=offseason&deload=1&boringButBigDeloadOption=3x10x50'
        )
  return url


def _get_page(url):
  # Start Firefox in Headless mode, so that it doesn't open a browser window
  options = Options()
  options.headless = True
  # We need Selenium because the page requires JS to show the cycle info
  driver = webdriver.Firefox(executable_path="driver/geckodriver", options=options)
  driver.get(url)
  page = driver.page_source
  driver.quit()
  soup = BeautifulSoup(page, 'html.parser')
  return soup


def _extract_cycle_info(page):
  weeks = page.find_all('table', attrs={'class': 'week'})
  cycle_info = []
  for week in weeks:
    week_info = []
    cols = week.select('tbody tr td table.routine')
    for col in cols:
      col_info = {}
      rows = col.find_all(['th', 'td'])
      current_header = None
      for row in rows:
        # e.g. {"press": []}
        if row.name == 'th':
          current_header = ' '.join([word.capitalize() for word in row.text.split(' ')])
          col_info[current_header] = [] 
        # e.g. {"press": ["5x50", "5x60", ...]}
        elif row.name == 'td':
          text = row.text
          # Replace unicode cross character with the letter x and remove spaces
          text = text.replace(' × ', 'x')
          # Remove plate information
          text = text.split(' ')[0]
          col_info[current_header].append(text)
      week_info.append(col_info)
    cycle_info.append(week_info)
  return cycle_info


def _generate_csv(
  cycle_info, 
  header_replacements=[],
  scheme_replacements=[],
  days=['Monday', 'Wednesday', 'Thursday', 'Saturdays']
):
  def _generate_week_prelude(week_num):
    return f'Week {week_num},,Set 1,Set 2,Set 3,Set 4,Set 5,Set 6,How Many?,\n'


  def _generate_csv_for_day(day_info, day_idx):
    csv = days[day_idx]

    # Iterate over each object in the information for the day,
    # which is a mapping from exercise name to rep scheme.
    for exercise, rep_schemes in day_info.items():
      # Make header replacements if any exist.
      if exercise in header_replacements[day_idx]:
        exercise = header_replacements[day_idx][exercise]
      
      csv += f',{exercise},'

      # Make rep scheme replacements if any exist.
      if exercise in scheme_replacements:
        replacement = scheme_replacements[exercise]
        if isinstance(replacement, list):
          rep_schemes = replacement[:len(rep_schemes)]
        else:
          rep_schemes = [replacement] * len(rep_schemes)
  
      for set_x_rep in rep_schemes:
        csv += f'{set_x_rep},'
      
      csv += '\n'
    
    return csv


  def _generate_empty_line():
    return ',,,,,,,,,\n'


  csv = ''
  for week_idx in range(len(cycle_info)):
    csv += _generate_week_prelude(week_idx + 1)
    for day_idx in range(len(cycle_info[week_idx])):
      csv += _generate_csv_for_day(cycle_info[week_idx][day_idx], day_idx)
      csv += _generate_empty_line()

  return csv


def _load_config(path):
  with open(path, 'r') as stream:
    try:
      return yaml.safe_load(stream)
    except yaml.YAMLError as exc:
      print('Error occurred while reading config: ' + exc)


def _get_args():
  parser = argparse.ArgumentParser()
  parser.add_argument('-o', '--output', type=str, default='./artifacts/Cycle.csv', help='Path to output file')
  parser.add_argument('--config', type=str, default='./config.yaml', help='Path to config file')
  return parser.parse_args()


def main():
  args = _get_args()
  config = _load_config(args.config)

  url = _generate_url(config['form_options'])
  page = _get_page(url)
  cycle_info = _extract_cycle_info(page)
  csv = _generate_csv(
    cycle_info,
    header_replacements=config['header_replacements'],
    scheme_replacements=config['scheme_replacements']
  )
  
  Path('/'.join(args.output.split('/')[:-1])).mkdir(parents=True, exist_ok=True)
  with open(args.output, 'w') as output:
    output.write(csv)

main()